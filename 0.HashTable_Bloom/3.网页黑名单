
100亿条URL网页黑名单（每个URL占64B）
问题：
    给一个URL，判断URL是否在100亿条URL网页黑名单中
要求：
    该系统允许有万分之一以下的判断失误率
    使用的额外空间复杂度不要超过30GB
     
（1）方法1（经典解法）：哈希表HashSet----->哈希来，哈希去；每个机器帮你抗
    需要至少：64*100亿bit ≈≈≈≈640G
        分到多台机器上，哈希分流

面试官说，这样做有个缺点：浪费空间了，有没有更好的解法？
此时，问面试官一句，这个系统允许有很低的失误率么？面试官一听，小伙子上道了，
一般情况下，都会说允许！
    
（2）方法2：Bloom过滤器（使用空间极度减少，用一台机器就可以完成）
