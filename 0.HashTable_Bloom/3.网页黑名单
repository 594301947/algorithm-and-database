
100亿条URL网页黑名单（每个URL占64B）
问题：
    给一个URL，判断URL是否在100亿条URL网页黑名单中
要求：
    该系统允许有万分之一以下的判断失误率
    使用的额外空间复杂度不要超过30GB
     
（1）方法1（经典解法）：哈希表HashSet----->哈希来，哈希去；每个机器帮你抗
    需要至少：64*100亿bit ≈≈≈≈640G
        分到多台机器上，哈希分流

面试官说，这样做有个缺点：浪费空间了，有没有更好的解法？
此时，问面试官一句，这个系统允许有很低的失误率么？面试官一听，小伙子上道了，
一般情况下，都会说允许！
    
（2）方法2：Bloom过滤器（使用空间极度减少，用一台机器就可以完成）
分析：
    Bloom过滤器开辟空间的大小，就是bit数组的长度（与input的size大小无关）=-n*lnP/(ln2*ln2)约等于131，571，428，572约等于16G
答案：
    将每个URL经过K个哈希函数，映射到S域（M长度的bit数组），涂黑
    检查data是否出现过：将data经过K和哈希函数，映射到S域
        如果有一个位置没被涂黑，则data一定不在
        如果有一个位置被涂黑，则data可能在，极小可能不在
    
